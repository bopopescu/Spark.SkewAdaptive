[INFO ] [2015-07-02 13:06:48] [Logging$class:logInfo:59] Registering worker 10.0.0.42:51001 with 4 cores, 8.8 GB RAM
  [INFO ] [2015-07-02 13:06:49] [Logging$class:logInfo:59] Registering worker 10.0.0.39:53050 with 4 cores, 8.8 GB RAM
  [INFO ] [2015-07-02 13:06:58] [Logging$class:logInfo:59] Registering worker 10.0.0.41:54560 with 4 cores, 8.8 GB RAM
  [INFO ] [2015-07-02 13:07:27] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.42:51001 got disassociated, removing it.
  [INFO ] [2015-07-02 13:07:27] [Logging$class:logInfo:59] Removing worker worker-20150702130644-10.0.0.42-51001 on 10.0.0.42:51001
  [WARN ] [2015-07-02 13:07:27] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$2:apply$mcV$sp:71] Association with remote system [akka.tcp://sparkWorker@10.0.0.42:51001] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
  [INFO ] [2015-07-02 13:07:27] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.42:51001 got disassociated, removing it.
  [ERROR] [2015-07-02 13:07:28] [SignalLoggerHandler:handle:57] RECEIVED SIGNAL 15: SIGTERM
  [INFO ] [2015-07-02 13:07:28] [Logging$class:logInfo:59] Shutdown hook called
  [WARN ] [2015-07-02 13:07:28] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$2:apply$mcV$sp:71] Association with remote system [akka.tcp://sparkWorker@10.0.0.41:54560] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
  [WARN ] [2015-07-02 13:07:28] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$2:apply$mcV$sp:71] Association with remote system [akka.tcp://sparkWorker@10.0.0.39:53050] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
  [INFO ] [2015-07-02 13:07:28] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.41:54560 got disassociated, removing it.
  [INFO ] [2015-07-02 13:07:28] [Logging$class:logInfo:59] Removing worker worker-20150702130653-10.0.0.41-54560 on 10.0.0.41:54560
  [INFO ] [2015-07-02 13:07:28] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.41:54560 got disassociated, removing it.
  [INFO ] [2015-07-02 13:07:28] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.39:53050 got disassociated, removing it.
  [INFO ] [2015-07-02 13:07:28] [Logging$class:logInfo:59] Removing worker worker-20150702130644-10.0.0.39-53050 on 10.0.0.39:53050
  [INFO ] [2015-07-02 13:07:28] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.39:53050 got disassociated, removing it.
  [INFO ] [2015-07-02 13:07:33] [SignalLogger$:register:47] Registered signal handlers for [TERM, HUP, INT]
  [INFO ] [2015-07-02 13:07:32] [SignalLogger$:register:47] Registered signal handlers for [TERM, HUP, INT]
  [WARN ] [2015-07-02 13:07:33] [NativeCodeLoader:<clinit>:[INFO ] [2015-07-02 13:07:32] [SignalLogger$:register:47] Registered signal handlers for [TERM, HUP, INT]
  [WARN ] [2015-07-02 13:07:33] [NativeCodeLoader:<clinit>:62] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 13:07:33] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:07:33] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:07:33] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 13:07:34] [Slf4jLogger$$anonfun$receive$1:applyOrElse:80] Slf4jLogger started
  [INFO ] [2015-07-02 13:07:34] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Starting remoting
  [INFO ] [2015-07-02 13:07:34] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remoting started; listening on addresses :[akka.tcp://sparkWorker@10.0.0.41:35039]
  [INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Successfully started service 'sparkWorker' on port 35039.
  onfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Starting remoting
  [INFO ] [2015-07-02 13:07:34] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remoting started; listening on addresses :[akka.tcp://sparkWorker@10.0.0.39:47520]
  [INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Successfully started service 'sp[INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Starting Spark worker 10.0.0.42:57325 with 4 cores, 8.8 GB RAM
  [INFO ] [2[INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Starting Spark worker 10.0.0.39:47520 with 4 cores, 8.8 GB RAM
  [INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Running Spark version 1.4.0
  [INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Spark home: /home/spark/spark-1.3.1
  [INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Successfully started service 'WorkerUI' on port 8081.
  [INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Started WorkerWebUI at http://10.0.0.39:8081
  [INFO ] [2015-07-02 13:07:34] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 13:07:35] [Logging$class:logInfo:59] Successfully registered with master spark://spark1:7077
  [INFO ] [2015-07-02 13:23:27] [Logging$class:logInfo:59] Running Spark version 1.4.0
  [WARN ] [2015-07-02 13:23:28] [NativeCodeLoader:<clinit>:62] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 13:23:29] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:23:29] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:23:29] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 13:23:30] [Slf4jLogger$$anonfun$receive$1:applyOrElse:80] Slf4jLogger started
  [INFO ] [2015-07-02 13:23:30] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Starting remoting
  [INFO ] [2015-07-02 13:23:30] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.0.38:36689]
  [INFO ] [2015-07-02 13:23:30] [Logging$class:logInfo:59] Successfully started service 'sparkDriver' on port 36689.
  [INFO ] [2015-07-02 13:23:31] [Logging$class:logInfo:59] Registering MapOutputTracker
  [INFO ] [2015-07-02 13:23:31] [Logging$class:logInfo:59] Registering BlockManagerMaster
  [INFO ] [2015-07-02 13:23:32] [Logging$class:logInfo:59] Created local directory at /tmp/spark-95af9c27-c1bd-4f53-8997-01661f048546/blockmgr-8868b538-ff83-4cf0-aaed-96e31046a188
  [INFO ] [2015-07-02 13:23:32] [Logging$class:logInfo:59] MemoryStore started with capacity 530.3 MB
  [INFO ] [2015-07-02 13:23:33] [Logging$class:logInfo:59] HTTP File server directory is /tmp/spark-95af9c27-c1bd-4f53-8997-01661f048546/httpd-0c381a99-5a7f-4573-9a23-d245e6d3df56
  [INFO ] [2015-07-02 13:23:33] [Logging$class:logInfo:59] Starting HTTP Server
  [INFO ] [2015-07-02 13:23:33] [Logging$class:logInfo:59] Successfully started service 'HTTP file server' on port 58035.
  [INFO ] [2015-07-02 13:23:33] [Logging$class:logInfo:59] Registering OutputCommitCoordinator
  [INFO ] [2015-07-02 13:23:33] [Logging$class:logInfo:59] Successfully started service 'SparkUI' on port 4040.
  [INFO ] [2015-07-02 13:23:33] [Logging$class:logInfo:59] Started SparkUI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 13:23:34] [Logging$class:logInfo:59] Added JAR file:/home/spark/spark-1.3.1/./examples/target/scala-2.10/spark-examples_2.10-1.4.0.jar at http://10.0.0.38:58035/jars/spark-examples_2.10-1.4.0.jar with timestamp 1435814614174
  [INFO ] [2015-07-02 13:23:35] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Registering app PageRank
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Registered app PageRank with ID app-20150702132336-0000
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Launching executor app-20150702132336-0000/0 on worker worker-20150702130734-10.0.0.42-57325
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Connected to Spark cluster with app ID app-20150702132336-0000
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Launching executor app-20150702132336-0000/1 on worker worker-20150702130734-10.0.0.41-35039
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Launching executor app-20150702132336-0000/2 on worker worker-20150702130734-10.0.0.39-47520
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Executor added: app-20150702132336-0000/0 on worker-20150702130734-10.0.0.42-57325 (10.0.0.42:57325) with 4 cores
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Granted executor ID app-20150702132336-0000/0 on hostPort 10.0.0.42:57325 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Executor added: app-20150702132336-0000/1 on worker-20150702130734-10.0.0.41-35039 (10.0.0.41:35039) with 4 cores
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Granted executor ID app-20150702132336-0000/1 on hostPort 10.0.0.41:35039 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Executor added: app-20150702132336-0000/2 on worker-20150702130734-10.0.0.39-47520 (10.0.0.39:47520) with 4 cores
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Granted executor ID app-20150702132336-0000/2 on hostPort 10.0.0.39:47520 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Executor updated: app-20150702132336-0000/0 is now RUNNING
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Executor updated: app-20150702132336-0000/1 is now RUNNING
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Executor updated: app-20150702132336-0000/2 is now RUNNING
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55505.
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Server created on 55505
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Trying to register BlockManager
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Registering block manager 10.0.0.38:55505 with 530.3 MB RAM, BlockManagerId(driver, 10.0.0.38, 55505)
  [INFO ] [2015-07-02 13:23:36] [Logging$class:logInfo:59] Registered BlockManager
  [INFO ] [2015-07-02 13:23:38] [Logging$class:logInfo:59] Logging events to file:///home/spark/history-spark/app-20150702132336-0000
  [INFO ] [2015-07-02 13:23:38] [Logging$class:logInfo:59] SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
  [INFO ] [2015-07-02 13:23:41] [Logging$class:logInfo:59] ensureFreeSpace(147968) called with curMem=0, maxMem=556038881
  [INFO ] [2015-07-02 13:23:41] [Logging$class:logInfo:59] Block broadcast_0 stored as values in memory (estimated size 144.5 KB, free 530.1 MB)
  [INFO ] [2015-07-02 13:23:42] [Logging$class:logInfo:59] ensureFreeSpace(14084) called with curMem=147968, maxMem=556038881
  [INFO ] [2015-07-02 13:23:42] [Logging$class:logInfo:59] Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.8 KB, free 530.1 MB)
  [INFO ] [2015-07-02 13:23:42] [Logging$class:logInfo:59] Added broadcast_0_piece0 in memory on 10.0.0.38:55505 (size: 13.8 KB, free: 530.3 MB)
  [INFO ] [2015-07-02 13:23:42] [Logging$class:logInfo:59] Created broadcast 0 from textFile at SparkPageRank.scala:56
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Invoking stop() from shutdown hook
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Stopped Spark web UI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Stopping DAGScheduler
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Shutting down all executors
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Asking each executor to shut down
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Received unregister request from application app-20150702132336-0000
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Removing app app-20150702132336-0000
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] MapOutputTrackerMasterEndpoint stopped!
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] path = /tmp/spark-95af9c27-c1bd-4f53-8997-01661f048546/blockmgr-8868b538-ff83-4cf0-aaed-96e31046a188, already present as root for deletion.
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] MemoryStore cleared
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] BlockManager stopped
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] BlockManagerMaster stopped
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] OutputCommitCoordinator stopped!
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Successfully stopped SparkContext
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Shutdown hook called
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Deleting directory /tmp/spark-95af9c27-c1bd-4f53-8997-01661f048546
  [INFO ] [2015-07-02 13:23:47] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Shutting down remote daemon.
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:23:47] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [WARN ] [2015-07-02 13:23:47] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$2:apply$mcV$sp:71] Association with remote system [akka.tcp://sparkDriver@10.0.0.38:36689] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
  [INFO ] [2015-07-02 13:23:48] [Logging$class:logInfo:59] akka.tcp://sparkDriver@10.0.0.38:36689 got disassociated, removing it.
  [INFO ] [2015-07-02 13:23:48] [Logging$class:logInfo:59] akka.tcp://sparkDriver@10.0.0.38:36689 got disassociated, removing it.
  [INFO ] [2015-07-02 13:23:48] [Logging$class:logInfo:59] Asked to launch executor app-20150702132336-0000/0 for PageRank
  [INFO ] [2015-07-02 13:23:49] [Logging$class:logInfo:59] Asked to kill executor app-20150702132336-0000/0
  [INFO ] [2015-07-02 13:23:49] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=36689" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:36689/user/CoarseGrainedScheduler" "--executor-id" "0" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702132336-0000" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:57325/user/Worker"
  [INFO ] [2015-07-02 13:23:49] [Logging$class:logInfo:59] Runner thread for executor app-20150702132336-0000/0 interrupted
  [INFO ] [2015-07-02 13:23:49] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 13:23:49] [Logging$class:logInfo:59] Executor app-20150702132336-0000/0 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 13:23:49] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702132336-0000
  /spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=36689" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:36689/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702132336-0000" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:35039/user/Worker"
  9:47520/user/Worker"
  [INFO ] [2015-07-02 13:24:17] [Logging$class:logInfo:59] Runner thread for executor app-20150702132336-0000/2 interrupted
  [INFO ] [2015-07-02 13:24:17] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 13:24:17] [Logging$class:logInfo:59] Executor app-20150702132336-0000/2 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 13:24:17] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702132336-0000
  [INFO ] [2015-07-02 13:24:20] [Logging$class:logInfo:59] Runner thread for executor app-20150702132336-0000/1 interrupted
  [INFO ] [2015-07-02 13:24:21] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 13:24:21] [Logging$class:logInfo:59] Executor app-20150702132336-0000/1 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 13:24:21] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702132336-0000
  [INFO ] [2015-07-02 13:30:42] [Logging$class:logInfo:59] Running Spark version 1.4.0
  [WARN ] [2015-07-02 13:30:43] [NativeCodeLoader:<clinit>:62] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 13:30:43] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:30:43] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:30:43] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 13:30:44] [Slf4jLogger$$anonfun$receive$1:applyOrElse:80] Slf4jLogger started
  [INFO ] [2015-07-02 13:30:44] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Starting remoting
  [INFO ] [2015-07-02 13:30:45] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.0.38:38581]
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Successfully started service 'sparkDriver' on port 38581.
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Registering MapOutputTracker
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Registering BlockManagerMaster
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Created local directory at /tmp/spark-8bd25a6b-8ad0-495e-b9c2-8ea71c3c8715/blockmgr-16844caf-cc69-4ec7-aed5-c64048d2cd29
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] MemoryStore started with capacity 530.3 MB
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] HTTP File server directory is /tmp/spark-8bd25a6b-8ad0-495e-b9c2-8ea71c3c8715/httpd-783c47c9-4382-4ba3-a9c2-d813efe72118
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Starting HTTP Server
  [INFO ] [2015-07-02 13:30:46] [Logging$class:logInfo:59] Successfully started service 'HTTP file server' on port 42896.
  [INFO ] [2015-07-02 13:30:46] [Logging$class:logInfo:59] Registering OutputCommitCoordinator
  [INFO ] [2015-07-02 13:30:46] [Logging$class:logInfo:59] Successfully started service 'SparkUI' on port 4040.
  [INFO ] [2015-07-02 13:30:46] [Logging$class:logInfo:59] Started SparkUI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 13:30:46] [Logging$class:logInfo:59] Added JAR file:/home/spark/spark-1.3.1/./examples/target/scala-2.10/spark-examples_2.10-1.4.0.jar at http://10.0.0.38:42896/jars/spark-examples_2.10-1.4.0.jar with timestamp 1435815046599
  [INFO ] [2015-07-02 13:30:47] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 13:30:47] [Logging$class:logInfo:59] Registering app PageRank
  [INFO ] [2015-07-02 13:30:47] [Logging$class:logInfo:59] Registered app PageRank with ID app-20150702133047-0001
  [INFO ] [2015-07-02 13:30:47] [Logging$class:logInfo:59] Launching executor app-20150702133047-0001/0 on worker worker-20150702130734-10.0.0.42-57325
  [INFO ] [2015-07-02 13:30:47] [Logging$class:logInfo:59] Launching executor app-20150702133047-0001/1 on worker worker-20150702130734-10.0.0.41-35039
  [INFO ] [2015-07-02 13:30:47] [Logging$class:logInfo:59] Launching executor app-20150702133047-0001/2 on worker worker-20150702130734-10.0.0.39-47520
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Asked to launch executor app-20150702133047-0001/0 for PageRank
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=38581" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:38581/user/CoarseGrainedScheduler" "--executor-id" "0" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702133047-0001" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:57325/user/Worker"
  520) with 4 cores
  [INFO ] [2015-07-02 13:30:45] [Logging$class:logInfo:59] Asked to launch executor app-20150702133047-0001/2 for PageRank
  [INFO ] [2015-07-02 13:30:46] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=38581" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:38581/user/CoarseGrainedScheduler" "--executor-id" "2" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702133047-0001" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:47520/user/Worker"
  tarted service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50057.
  [INFO ] [2015-07-02 13:30:48] [Logging$class:logInfo:59] Server created on 50057
  [INFO ] [2015-07-02 13:30:48] [Logging$class:logInfo:59] Trying to register BlockManager
  [INFO ] [2015-07-02 13:30:48] [Logging$class:logInfo:59] Registering block manager 10.0.0.38:50057 with 530.3 MB RAM, BlockManagerId(driver, 10.0.0.38, 50057)
  [INFO ] [2015-07-02 13:30:48] [Logging$class:logInfo:59] Registered BlockManager
  [INFO ] [2015-07-02 13:30:49] [Logging$class:logInfo:59] Logging events to file:///home/spark/history-spark/app-20150702133047-0001
  [INFO ] [2015-07-02 13:30:49] [Logging$class:logInfo:59] SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
  [INFO ] [2015-07-02 13:30:51] [Logging$class:logInfo:59] ensureFreeSpace(147968) called with curMem=0, maxMem=556038881
  [INFO ] [2015-07-02 13:30:51] [Logging$class:logInfo:59] Block broadcast_0 stored as values in memory (estimated size 144.5 KB, free 530.1 MB)
  [INFO ] [2015-07-02 13:30:52] [Logging$class:logInfo:59] ensureFreeSpace(14084) called with curMem=147968, maxMem=556038881
  [INFO ] [2015-07-02 13:30:52] [Logging$class:logInfo:59] Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.8 KB, free 530.1 MB)
  [INFO ] [2015-07-02 13:30:52] [Logging$class:logInfo:59] Added broadcast_0_piece0 in memory on 10.0.0.38:50057 (size: 13.8 KB, free: 530.3 MB)
  [INFO ] [2015-07-02 13:30:52] [Logging$class:logInfo:59] Created broadcast 0 from textFile at SparkPageRank.scala:56
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Invoking stop() from shutdown hook
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Stopped Spark web UI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Stopping DAGScheduler
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Shutting down all executors
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Asking each executor to shut down
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Received unregister request from application app-20150702133047-0001
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Removing app app-20150702133047-0001
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] MapOutputTrackerMasterEndpoint stopped!
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] path = /tmp/spark-8bd25a6b-8ad0-495e-b9c2-8ea71c3c8715/blockmgr-16844caf-cc69-4ec7-aed5-c64048d2cd29, already present as root for deletion.
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] MemoryStore cleared
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] BlockManager stopped
  [INFO ] [2015-07-02 13:30:55] [Logging$class:logInfo:59] BlockManagerMaster stopped
  [INFO ] [2015-07-02 13:30:52] [Logging$class:logInfo:59] Asked to kill executor app-20150702133047-0001/2
  [INFO ] [2015-07-02 13:30:53] [Logging$class:logInfo:59] Runner thread for executor app-20150702133047-0001/2 interrupted
  [INFO ] [2015-07-02 13:30:53] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 13:30:53] [Logging$class:logInfo:59] Executor app-20150702133047-0001/2 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 13:30:53] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702133047-0001
   executor app-20150702133047-0001/1 interrupted
  [INFO ] [2015-07-02 13:30:53] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 13:30:54] [Logging$class:logInfo:59] Executor app-20150702133047-0001/1 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 13:30:54] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702133047-0001
  address is now gated for [5000] ms. Reason is: [Disassociated].
  [WARN ] [2015-07-02 13:30:57] [Logging$class:logWarning:71] Got status update for unknown executor app-20150702133047-0001/1
  [INFO ] [2015-07-02 13:30:57] [Logging$class:logInfo:59] Executor app-20150702133047-0001/0 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 13:30:57] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702133047-0001
  [ERROR] [2015-07-02 13:41:21] [SignalLoggerHandler:handle:57] RECEIVED SIGNAL 15: SIGTERM
  [INFO ] [2015-07-02 13:41:21] [Logging$class:logInfo:59] Shutdown hook called
  [INFO ] [2015-07-02 13:41:21] [Logging$class:logInfo:59] Deleting directory /tmp/spark-dbfaf090-4ca6-4f81-ad06-21432ba5f794
  [INFO ] [2015-07-02 13:41:24] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.42:57325 got disassociated, removing it.
  [WARN ] [2015-07-02 13:41:24] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$2:apply$mcV$sp:71] Association with remote system [akka.tcp://sparkWorker@10.0.0.42:57325] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
  [INFO ] [2015-07-02 13:41:24] [Logging$class:logInfo:59] Removing worker worker-20150702130734-10.0.0.42-57325 on 10.0.0.42:57325
  [INFO ] [2015-07-02 13:41:24] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.42:57325 got disassociated, removing it.
  [ERROR] [2015-07-02 13:41:24] [SignalLoggerHandler:handle:57] RECEIVED SIGNAL 15: SIGTERM
  [INFO ] [2015-07-02 13:41:24] [Logging$class:logInfo:59] Shutdown hook called
  [INFO ] [2015-07-02 13:41:24] [Logging$class:logInfo:59] Deleting directory /tmp/spark-2f6f207a-54bd-4088-a721-048de0b6f59c
  [INFO ] [2015-07-02 13:41:27] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.41:35039 got disassociated, removing it.
  [INFO ] [2015-07-02 13:41:27] [Logging$class:logInfo:59] Removing worker worker-20150702130734-10.0.0.41-35039 on 10.0.0.41:35039
  [WARN ] [2015-07-02 13:41:27] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$2:apply$mcV$sp:71] Association with remote system [akka.tcp://sparkWorker@10.0.0.41:35039] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
  [INFO ] [2015-07-02 13:41:27] [Logging$class:logInfo:59] akka.tcp://sparkWorker@10.0.0.41:35039 got disassociated, removing it.
  [ERROR] [2015-07-02 13:41:25] [SignalLoggerHandler:handle:57] RECEIVED SIGNAL 15: SIGTERM
  [INFO ] [2015-07-02 13:41:25] [Logging$class:logInfo:59] Shutdown hook called
  [INFO ] [2015-07-02 13:41:25] [Logging$class:logInfo:59] Deleting directory /tmp/spark-6ee00fc3-5546-4438-9009-c3e30c756162
  [INFO ] [2015-07-02 13:41:35] [SignalLogger$:register:47] Registered signal handlers for [TERM, HUP, INT]
  [WARN ] [2015-07-02 13:41:36] [NativeCodeLoader:<clinit>:62] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 13:41:34] [SignalLogger$:register:47] Registered signal handlers for [TERM, HUP, INT]
  [WARN ] [2015-07-02 13:41:35] [NativeCodeLoader:<clinit>:62] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 13:41:35] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:41:35] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:41:35] [Logging$class:logInfo:59] SecurityManag[INFO ] [2015-07-02 13:41:35] [SignalLogger$:register:47] Registered signal handlers for [TERM, HUP, INT]
  [WARN ] [2015-07-02 13:41:35] [NativeCodeLoader:<clinit>:62] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 13:41:36] [Slf4jLogger$$anonfun$receive$1:applyOrElse:80] Slf[INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Starting Spark worker 10.0.0.42:55556 with 4 cores, 8.8 GB RAM
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Running Spark version 1.4.0
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Spark home: /home/spark/spark-1.3.1
  [INFO ] [2015-07-02 13:41:36] [Logging$class:logInfo:59] Successfully started service 'WorkerUI' on port 8081.
  [INFO ] [2015-07-02 13:41:36[INFO ] [2015-07-02 13:41:37] [Logging$class:logInfo:59] Starting Spark worker 10.0.0.41:54339 with 4 cores, 8.8 GB RAM
  [INFO ] [2015-07-02 13:41:37] [Logging$class:logInfo:59] Running Spark version 1.4.0
  [INFO ] [2015-07-02 13:41:37] [Logging$class:logInfo:59] Spark home: /home/spark/spark-1.3.1
  [INFO ] [2015-07-02 13:41:37] [Logging$class:logInfo:59] Successfully started service 'WorkerUI' on port 8081.
  [INFO ] [2015-07-02 13:41:37] [Logging$class:logInfo:59] Started WorkerWebUI at http://10.0.0.41:8081
  [INFO ] [2015-07-02 13:41:37] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 13:41:37] [Logging$class:logInfo:59] Successfully registered with master spark://spark1:7077
  class:logInfo:59] Successfully started service 'WorkerUI' on port 8081.
  [INFO ] [2015-07-02 13:41:39] [Logging$class:logInfo:59] Started WorkerWebUI at http://10.0.0.39:8081
  [INFO ] [2015-07-02 13:41:39] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 13:41:40] [Logging$class:logInfo:59] Successfully registered with master spark://spark1:7077
  7-02 13:41:47] [Slf4jLogger$$anonfun$receive$1:applyOrElse:80] Slf4jLogger started
  [INFO ] [2015-07-02 13:41:47] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Starting remoting
  [INFO ] [2015-07-02 13:41:47] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.0.38:55615]
  [INFO ] [2015-07-02 13:41:47] [Logging$class:logInfo:59] Successfully started service 'sparkDriver' on port 55615.
  [INFO ] [2015-07-02 13:41:47] [Logging$class:logInfo:59] Registering MapOutputTracker
  [INFO ] [2015-07-02 13:41:47] [Logging$class:logInfo:59] Registering BlockManagerMaster
  [INFO ] [2015-07-02 13:41:47] [Logging$class:logInfo:59] Created local directory at /tmp/spark-c182520d-b140-408e-bc9f-d93433823075/blockmgr-bb33e7a6-ce7a-4a24-83d7-e26f07b5ecc7
  [INFO ] [2015-07-02 13:41:47] [Logging$class:logInfo:59] MemoryStore started with capacity 530.3 MB
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] HTTP File server directory is /tmp/spark-c182520d-b140-408e-bc9f-d93433823075/httpd-76691e47-a9c8-47e1-93a8-543d65318fd1
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Starting HTTP Server
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Successfully started service 'HTTP file server' on port 55305.
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Registering OutputCommitCoordinator
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Successfully started service 'SparkUI' on port 4040.
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Started SparkUI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Added JAR file:/home/spark/spark-1.3.1/./examples/target/scala-2.10/spark-examples_2.10-1.4.0.jar at http://10.0.0.38:55305/jars/spark-examples_2.10-1.4.0.jar with timestamp 1435815708516
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Registering app PageRank
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Registered app PageRank with ID app-20150702134148-0000
  [INFO ] [2015-07-02 13:41:48] [Logging$class:logInfo:59] Connected to Spark cluster with app ID app-20150702134148-0000
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Launching executor app-20150702134148-0000/0 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Launching executor app-20150702134148-0000/1 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Launching executor app-20150702134148-0000/2 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Executor added: app-20150702134148-0000/0 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Granted executor ID app-20150702134148-0000/0 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Executor added: app-20150702134148-0000/1 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Granted executor ID app-20150702134148-0000/1 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Executor added: app-20150702134148-0000/2 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Granted executor ID app-20150702134148-0000/2 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 13:41:46] [Logging$class:logInfo:59] Asked to launch executor app-20150702134148-0000/1 for PageRank
  [INFO ] [2015-07-02 13:41:46] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark[INFO ] [2015-07-02 13:41:46] [Logging$class:logInfo:59] Asked to launch executor app-20150702134148-0000/2 for PageRa[INFO ] [2015-07-02 13:41:46] [Logging$class:logInfo:59] Asked to launch executor app-20150702134148-0000/0 for PageRank
  [INFO ] [2015-07-02 13:41:46] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=55615" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:55615/user/CoarseGrainedScheduler" "--executor-id" "0" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702134148-0000" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42893.
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Server created on 42893
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Trying to register BlockManager
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Registering block manager 10.0.0.38:42893 with 530.3 MB RAM, BlockManagerId(driver, 10.0.0.38, 42893)
  [INFO ] [2015-07-02 13:41:49] [Logging$class:logInfo:59] Registered BlockManager
  [INFO ] [2015-07-02 13:41:50] [Logging$class:logInfo:59] Logging events to file:///home/spark/history-spark/app-20150702134148-0000
  [INFO ] [2015-07-02 13:41:50] [Logging$class:logInfo:59] SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
  [INFO ] [2015-07-02 13:41:51] [Logging$class:logInfo:59] ensureFreeSpace(147800) called with curMem=0, maxMem=556038881
  [INFO ] [2015-07-02 13:41:51] [Logging$class:logInfo:59] Block broadcast_0 stored as values in memory (estimated size 144.3 KB, free 530.1 MB)
  [INFO ] [2015-07-02 13:41:51] [Logging$class:logInfo:59] ensureFreeSpace(14216) called with curMem=147800, maxMem=556038881
  [INFO ] [2015-07-02 13:41:51] [Logging$class:logInfo:59] Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.9 KB, free 530.1 MB)
  [INFO ] [2015-07-02 13:41:51] [Logging$class:logInfo:59] Added broadcast_0_piece0 in memory on 10.0.0.38:42893 (size: 13.9 KB, free: 530.3 MB)
  [INFO ] [2015-07-02 13:41:51] [Logging$class:logInfo:59] Created broadcast 0 from textFile at SparkPageRank.scala:56
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Invoking stop() from shutdown hook
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Stopped Spark web UI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Stopping DAGScheduler
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Shutting down all executors
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Asking each executor to shut down
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Received unregister request from application app-20150702134148-0000
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Removing app app-20150702134148-0000
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] MapOutputTrackerMasterEndpoint stopped!
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] path = /tmp/spark-c182520d-b140-408e-bc9f-d93433823075/blockmgr-bb33e7a6-ce7a-4a24-83d7-e26f07b5ecc7, already present as root for deletion.
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] MemoryStore cleared
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] BlockManager stopped
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] BlockManagerMaster stopped
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] OutputCommitCoordinator stopped!
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Successfully stopped SparkContext
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Shutdown hook called
  [INFO ] [2015-07-02 13:41:52] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Shutting down remote daemon.
  [INFO ] [2015-07-02 13:41:52] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remote daemon shut down; proceeding with flushing remote transports.
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Deleting directory /tmp/spark-c182520d-b140-408e-bc9f-d93433823075
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 13:41:52] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [WARN ] [2015-07-02 13:41:53] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$2:apply$mcV$sp:71] Association with remote system [akka.tcp://sparkDriver@10.0.0.38:55615] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
  [INFO ] [2015-07-02 13:41:53] [Logging$class:logInfo:59] akka.tcp://sparkDriver@10.0.0.38:55615 got disassociated, removing it.
  [INFO ] [2015-07-02 13:41:53] [Logging$class:logInfo:59] akka.tcp://sparkDriver@10.0.0.38:55615 got disassociated, removing it.
  [INFO ] [2015-07-02 13:41:50] [Logging$class:logInfo:59] Asked to kill executor app-20150702134148-0000/2
  [INFO ] [2015-07-02 13:41:50] [Logging$class:logInfo:59] Runner thread for executor app-20150702134148-0000/2 interrupted
  [INFO ] [2015-07-02 13:41:50] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 13:41:53] [Logging$class:logInfo:59] Executor app-20150702134148-0000/1 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 13:41:53] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702134148-0000
  [INFO ] [2015-07-02 14:01:12] [Logging$class:logInfo:59] Running Spark version 1.4.0
  [WARN ] [2015-07-02 14:01:13] [NativeCodeLoader:<clinit>:62] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 14:01:14] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 14:01:14] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 14:01:14] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 14:01:15] [Slf4jLogger$$anonfun$receive$1:applyOrElse:80] Slf4jLogger started
  [INFO ] [2015-07-02 14:01:15] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Starting remoting
  [INFO ] [2015-07-02 14:01:16] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.0.38:40462]
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Successfully started service 'sparkDriver' on port 40462.
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Registering MapOutputTracker
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Registering BlockManagerMaster
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Created local directory at /tmp/spark-7f270133-951f-4fb2-a500-2ed0532e046b/blockmgr-560f909f-07c2-48f5-96ea-dc59cea253f2
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] MemoryStore started with capacity 530.3 MB
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] HTTP File server directory is /tmp/spark-7f270133-951f-4fb2-a500-2ed0532e046b/httpd-1bdf6fec-3f84-44e6-a67b-71ccc03b52c4
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Starting HTTP Server
  [INFO ] [2015-07-02 14:01:17] [Logging$class:logInfo:59] Successfully started service 'HTTP file server' on port 47122.
  [INFO ] [2015-07-02 14:01:17] [Logging$class:logInfo:59] Registering OutputCommitCoordinator
  [INFO ] [2015-07-02 14:01:17] [Logging$class:logInfo:59] Successfully started service 'SparkUI' on port 4040.
  [INFO ] [2015-07-02 14:01:17] [Logging$class:logInfo:59] Started SparkUI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 14:01:17] [Logging$class:logInfo:59] Added JAR file:/home/spark/spark-1.3.1/./examples/target/scala-2.10/spark-examples_2.10-1.4.0.jar at http://10.0.0.38:47122/jars/spark-examples_2.10-1.4.0.jar with timestamp 1435816877780
  [INFO ] [2015-07-02 14:01:17] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Registering app PageRank
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Registered app PageRank with ID app-20150702140119-0001
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Launching executor app-20150702140119-0001/0 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Launching executor app-20150702140119-0001/1 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Launching executor app-20150702140119-0001/2 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Asked to launch executor app-20150702140119-0001/0 for PageRank
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=40462" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:40462/user/CoarseGrainedScheduler" "--executor-id" "0" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702140119-0001" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Granted executor ID app-20150702140119-0001/0 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Executor added: app-20150702140119-0001/1 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Granted executor ID app-20150702140119-0001/1 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Executor added: app-20150702140119-0001/2 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Granted executor ID app-20150702140119-0001/2 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Executor updated: app-20150702140119-0001/1 is now LOADING
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Executor updated: app-20150702140119-0001/0 is now LOADING
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Executor updated: app-20150702140119-0001/0 is now RUNNING
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Executor updated: app-20150702140119-0001/1 is now RUNNING
  [INFO ] [2015-07-02 14:01:19] [Logging$class:logInfo:59] Executor updated: app-20150702140119-0001/2 is now RUNNING
  [INFO ] [2015-07-02 14:01:16] [Logging$class:logInfo:59] Asked to launch executor app-20150702140119-0001/2 for PageRank
  [INFO ] [2015-07-02 14:01:17] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=40462" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:40462/user/CoarseGrainedScheduler" "--executor-id" "2" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702140119-0001" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  [INFO ] [2015-07-02 14:01:20] [Logging$class:logInfo:59] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57950.
  [INFO ] [2015-07-02 14:01:20] [Logging$class:logInfo:59] Server created on 57950
  [INFO ] [2015-07-02 14:01:20] [Logging$class:logInfo:59] Trying to register BlockManager
  [INFO ] [2015-07-02 14:01:20] [Logging$class:logInfo:59] Registering block manager 10.0.0.38:57950 with 530.3 MB RAM, BlockManagerId(driver, 10.0.0.38, 57950)
  [INFO ] [2015-07-02 14:01:20] [Logging$class:logInfo:59] Registered BlockManager
  [INFO ] [2015-07-02 14:01:24] [Logging$class:logInfo:59] Logging events to file:///home/spark/history-spark/app-20150702140119-0001
  [INFO ] [2015-07-02 14:01:25] [Logging$class:logInfo:59] SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
  [INFO ] [2015-07-02 14:01:32] [Logging$class:logInfo:59] ensureFreeSpace(147800) called with curMem=0, maxMem=556038881
  [INFO ] [2015-07-02 14:01:32] [Logging$class:logInfo:59] Block broadcast_0 stored as values in memory (estimated size 144.3 KB, free 530.1 MB)
  [INFO ] [2015-07-02 14:01:34] [Logging$class:logInfo:59] ensureFreeSpace(14216) called with curMem=147800, maxMem=556038881
  [INFO ] [2015-07-02 14:01:34] [Logging$class:logInfo:59] Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.9 KB, free 530.1 MB)
  [INFO ] [2015-07-02 14:01:34] [Logging$class:logInfo:59] Added broadcast_0_piece0 in memory on 10.0.0.38:57950 (size: 13.9 KB, free: 530.3 MB)
  [INFO ] [2015-07-02 14:01:34] [Logging$class:logInfo:59] Created broadcast 0 from textFile at SparkPageRank.scala:56
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Invoking stop() from shutdown hook
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Stopped Spark web UI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Stopping DAGScheduler
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Shutting down all executors
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Asking each executor to shut down
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] MapOutputTrackerMasterEndpoint stopped!
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Received unregister request from application app-20150702140119-0001
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] path = /tmp/spark-7f270133-951f-4fb2-a500-2ed0532e046b/blockmgr-560f909f-07c2-48f5-96ea-dc59cea253f2, already present as root for deletion.
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] MemoryStore cleared
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] BlockManager stopped
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Removing app app-20150702140119-0001
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] BlockManagerMaster stopped
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] OutputCommitCoordinator stopped!
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Successfully stopped SparkContext
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Shutdown hook called
  [INFO ] [2015-07-02 14:01:39] [Logging$class:logInfo:59] Deleting directory /tmp/spark-7f270133-951f-4fb2-a500-2ed0532e046b
  [INFO ] [2015-07-02 14:01:39] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Shutting down remote daemon.
  [INFO ] [2015-07-02 14:01:39] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remote daemon shut down; proceeding with flushing remote transports.
  [INFO ] [2015-07-02 14:01:42] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 14:01:42] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 14:01:42] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 14:01:48] [Logging$class:logInfo:59] Asked to kill executor app-20150702140119-0001/0
  [INFO ] [2015-07-02 14:01:48] [Logging$class:logInfo:59] Runner thread for executor app-20150702140119-0001/0 interrupted
  [INFO ] [2015-07-02 14:01:49] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 14:01:49] [Logging$class:logInfo:59] Executor app-201507[INFO ] [2015-07-02 14:01:52] [Logging$class:logInfo:59] Executor app-20150702140119-0001/2 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 14:01:52] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702140119-0001
  -0001/1 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 14:01:50] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702140119-0001
  [INFO ] [2015-07-02 14:53:28] [Logging$class:logInfo:59] Running Spark version 1.4.0
  [INFO ] [2015-07-02 14:53:29] [Logging$class:logInfo:59] Changing view acls to: spark
  [INFO ] [2015-07-02 14:53:29] [Logging$class:logInfo:59] Changing modify acls to: spark
  [INFO ] [2015-07-02 14:53:29] [Logging$class:logInfo:59] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
  [INFO ] [2015-07-02 14:53:30] [Slf4jLogger$$anonfun$receive$1:applyOrElse:80] Slf4jLogger started
  [INFO ] [2015-07-02 14:53:30] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Starting remoting
  [INFO ] [2015-07-02 14:53:30] [Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:apply$mcV$sp:74] Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.0.38:60939]
  [INFO ] [2015-07-02 14:53:30] [Logging$class:logInfo:59] Successfully started service 'sparkDriver' on port 60939.
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Registering MapOutputTracker
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Registering BlockManagerMaster
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Created local directory at /tmp/spark-841310c3-faa1-42c0-adfe-538b17386b10/blockmgr-8b20f044-0805-452a-af6c-540fd61c14c7
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] MemoryStore started with capacity 530.3 MB
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] HTTP File server directory is /tmp/spark-841310c3-faa1-42c0-adfe-538b17386b10/httpd-d7402abc-e4d4-4254-b4d8-11d204a7bb9f
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Starting HTTP Server
  [INFO ] [2015-07-02 14:53:31] [Server:doStart:272] jetty-8.y.z-SNAPSHOT
  [INFO ] [2015-07-02 14:53:31] [AbstractConnector:doStart:338] Started SocketConnector@0.0.0.0:55328
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Successfully started service 'HTTP file server' on port 55328.
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Registering OutputCommitCoordinator
  [INFO ] [2015-07-02 14:53:31] [Server:doStart:272] jetty-8.y.z-SNAPSHOT
  [INFO ] [2015-07-02 14:53:31] [AbstractConnector:doStart:338] Started SelectChannelConnector@0.0.0.0:4040
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Successfully started service 'SparkUI' on port 4040.
  [INFO ] [2015-07-02 14:53:31] [Logging$class:logInfo:59] Started SparkUI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 14:53:32] [Logging$class:logInfo:59] Added JAR file:/home/spark/spark-1.3.1/./examples/target/scala-2.10/spark-examples-1.4.0-hadoop1.0.4.jar at http://10.0.0.38:55328/jars/spark-examples-1.4.0-hadoop1.0.4.jar with timestamp 1435820012292
  [INFO ] [2015-07-02 14:53:32] [Logging$class:logInfo:59] Connecting to master akka.tcp://sparkMaster@spark1:7077/user/Master...
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Registering app PageRank
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Registered app PageRank with ID app-20150702145346-0002
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/0 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/1 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/2 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:53:43] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/0 for PageRank
  [INFO ] [2015-07-02 14:53:43] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "0" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  15-07-02 14:53:46] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/2 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/1 is now LOADING
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/0 is now RUNNING
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/0 is now LOADING
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/1 is now RUNNING
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/2 is now RUNNING
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/2 is now LOADING
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59681.
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Server created on 59681
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Trying to register BlockManager
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Registering block manager 10.0.0.38:59681 with 530.3 MB RAM, BlockManagerId(driver, 10.0.0.38, 59681)
  [INFO ] [2015-07-02 14:53:46] [Logging$class:logInfo:59] Registered BlockManager
  [WARN ] [2015-07-02 14:53:47] [NativeCodeLoader:<clinit>:52] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  [INFO ] [2015-07-02 14:53:47] [Logging$class:logInfo:59] Logging events to file:///home/spark/history-spark/app-20150702145346-0002
  [INFO ] [2015-07-02 14:53:47] [Logging$class:logInfo:59] SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
  [INFO ] [2015-07-02 14:53:49] [Logging$class:logInfo:59] ensureFreeSpace(33416) called with curMem=0, maxMem=556038881
  [INFO ] [2015-07-02 14:53:49] [Logging$class:logInfo:59] Block broadcast_0 stored as values in memory (estimated size 32.6 KB, free 530.2 MB)
  [INFO ] [2015-07-02 14:53:49] [Logging$class:logInfo:59] ensureFreeSpace(3643) called with curMem=33416, maxMem=556038881
  [INFO ] [2015-07-02 14:53:49] [Logging$class:logInfo:59] Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.6 KB, free 530.2 MB)
  [INFO ] [2015-07-02 14:53:49] [Logging$class:logInfo:59] Added broadcast_0_piece0 in memory on 10.0.0.38:59681 (size: 3.6 KB, free: 530.3 MB)
  [INFO ] [2015-07-02 14:53:49] [Logging$class:logInfo:59] Created broadcast 0 from textFile at SparkPageRank.scala:56
  [WARN ] [2015-07-02 14:53:51] [LoadSnappy:<clinit>:46] Snappy native library not loaded
  [INFO ] [2015-07-02 14:53:51] [FileInputFormat:listStatus:199] Total input paths to process : 1
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Starting job: collect at SparkPageRank.scala:71
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Registering RDD 3 (distinct at SparkPageRank.scala:60)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Registering RDD 5 (distinct at SparkPageRank.scala:60)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Registering RDD 12 (flatMap at SparkPageRank.scala:64)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Got job 0 (collect at SparkPageRank.scala:71) with 1 output partitions (allowLocal=false)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Final stage: ResultStage 3(collect at SparkPageRank.scala:71)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Parents of final stage: List(ShuffleMapStage 2)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Missing parents: List(ShuffleMapStage 2)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at SparkPageRank.scala:60), which has no missing parents
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] ensureFreeSpace(4024) called with curMem=37059, maxMem=556038881
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 530.2 MB)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] ensureFreeSpace(2289) called with curMem=41083, maxMem=556038881
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 530.2 MB)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Added broadcast_1_piece0 in memory on 10.0.0.38:59681 (size: 2.2 KB, free: 530.3 MB)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Created broadcast 1 from broadcast at DAGScheduler.scala:874
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at SparkPageRank.scala:60)
  [INFO ] [2015-07-02 14:53:53] [Logging$class:logInfo:59] Adding task set 0.0 with 1 tasks
  [INFO ] [2015-07-02 14:54:01] [Logging$class:logInfo:59] Executor app-20150702145346-0002/1 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:03] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/3 for PageRank
  [INFO ] [2015-07-02 14:54:03] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "3" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  ng$class:logInfo:59] Executor updated: app-20150702145346-0002/3 is now LOADING
  [WARN ] [2015-07-02 14:54:08] [Logging$class:logWarning:71] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
  [INFO ] [2015-07-02 14:54:17] [Logging$class:logInfo:59] Executor app-20150702145346-0002/3 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:18] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/4 for PageRank
  [INFO ] [2015-07-02 14:54:18] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "4" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  ng$class:logInfo:59] Executor updated: app-20150702145346-0002/4 is now LOADING
  [INFO ] [2015-07-02 14:54:18] [Logging$class:logInfo:59] Executor app-20150702145346-0002/4 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:18] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/5 for PageRank
  [INFO ] [2015-07-02 14:54:18] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "5" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  [INFO ] [2015-07-02 14:54:21] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/5 is now LOADING
  [INFO ] [2015-07-02 14:54:19] [Logging$class:logInfo:59] Executor app-20150702145346-0002/5 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:19] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/6 for PageRank
  [INFO ] [2015-07-02 14:54:19] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "6" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  ng$class:logInfo:59] Executor updated: app-20150702145346-0002/6 is now LOADING
  [INFO ] [2015-07-02 14:54:19] [Logging$class:logInfo:59] Executor app-20150702145346-0002/6 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:19] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/7 for PageRank
  [INFO ] [2015-07-02 14:54:19] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "7" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  ng$class:logInfo:59] Executor updated: app-20150702145346-0002/7 is now LOADING
  [INFO ] [2015-07-02 14:54:20] [Logging$class:logInfo:59] Executor app-20150702145346-0002/7 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:20] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/8 for PageRank
  [INFO ] [2015-07-02 14:54:20] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "8" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  ng$class:logInfo:59] Executor updated: app-20150702145346-0002/8 is now LOADING
  [WARN ] [2015-07-02 14:54:23] [Logging$class:logWarning:71] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
  [INFO ] [2015-07-02 14:54:22] [Logging$class:logInfo:59] Executor app-20150702145346-0002/2 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:24] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/9 for PageRank
  [INFO ] [2015-07-02 14:54:24] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "9" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  ng$class:logInfo:59] Executor updated: app-20150702145346-0002/9 is now LOADING
  [INFO ] [2015-07-02 14:54:25] [Logging$class:logInfo:59] Executor app-20150702145346-0002/0 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:25] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/10 for PageRank
  [INFO ] [2015-07-02 14:54:25] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "10" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  ging$class:logInfo:59] Executor updated: app-20150702145346-0002/10 is now LOADING
  [INFO ] [2015-07-02 14:54:26] [Logging$class:logInfo:59] Executor app-20150702145346-0002/10 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:26] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/12 for PageRank
  [INFO ] [2015-07-02 14:54:26] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "12" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  ing$class:logInfo:59] Executor updated: app-20150702145346-0002/11 is now RUNNING
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/10 because it is EXITED
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/12 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/10 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Executor app-20150702145346-0002/10 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:29] [Logging$class:logError:75] Asked to remove non-existent executor 10
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/12 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/12 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:26] [Logging$class:logInfo:59] Executor app-20150702145346-0002/11 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:26] [Logging$class:logInfo:59] Asked to la[INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Executor app-20150702145346-0002/12 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/14 for PageRank
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "14" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/13 is now LOADING
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Executor app-20150702145346-0002/13 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/15 for PageRank
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "15" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/14 is now RUNNING
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Executor app-20150702145346-0002/14 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/16 for PageRank
  [INFO ] [2015-07-02 14:54:27] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "16" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/15 is now LOADING
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/14 because it is EXITED
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/16 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/14 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor app-20150702145346-0002/14 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:30] [Logging$class:logError:75] Asked to remove non-existent executor 14
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/16 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/16 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/16 is now RUNNING
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/16 is now LOADING
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Executor app-20150702145346-0002/16 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/18 for PageRank
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "18" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/17 is now LOADING
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/16 because it is EXITED
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Executor app-20150702145346-0002/17 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/19 for PageRank
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "19" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  g$class:logInfo:59] Removing executor app-20150702145346-0002/17 because it is EXITED
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/19 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/17 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor app-20150702145346-0002/17 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:31] [Logging$class:logError:75] Asked to remove non-existent executor 17
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/19 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/19 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Executor app-20150702145346-0002/18 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Asked to la[INFO ] [2015-07-02 14:54:28] [Logging$class:logInfo:59] Executor app-20150702145346-0002/19 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/21 for PageRank
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "21" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/20 is now LOADING
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Executor app-20150702145346-0002/20 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/23 for PageRank
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "23" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/21 is now LOADING
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Executor app-20150702145346-0002/21 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/22 for PageRank
  [INFO ] [2015-07-02 14:54:29] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "22" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/22 is now RUNNING
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/20 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/20 because it is EXITED
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor app-20150702145346-0002/20 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:32] [Logging$class:logError:75] Asked to remove non-existent executor 20
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/23 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/23 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/23 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor app-20150702145346-0002/22 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Asked to la[INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor app-20150702145346-0002/23 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/25 for PageRank
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "25" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/24 is now LOADING
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/23 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor app-20150702145346-0002/23 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:32] [Logging$class:logError:75] Asked to remove non-existent executor 23
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/23 because it is EXITED
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/25 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/25 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/25 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor app-20150702145346-0002/24 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Asked to la[INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Executor app-20150702145346-0002/25 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/27 for PageRank
  [INFO ] [2015-07-02 14:54:30] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "27" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/26 is now LOADING
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/25 because it is EXITED
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/27 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/25 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor app-20150702145346-0002/25 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:33] [Logging$class:logError:75] Asked to remove non-existent executor 25
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/27 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/27 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/27 is now LOADING
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor app-20150702145346-0002/26 finished with state EXITED[INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor app-20150702145346-0002/27 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/29 for PageRank
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "29" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@[INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor app-20150702145346-0002/9 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/30 for PageRank
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "30" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/29 is now RUNNING
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/29 is now LOADING
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor app-20150702145346-0002/28 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/32 for PageRank
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "32" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  ing$class:logInfo:59] Executor updated: app-20150702145346-0002/30 is now RUNNING
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Executor app-20150702145346-0002/30 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/33 for PageRank
  [INFO ] [2015-07-02 14:54:31] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "33" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/31 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/28 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor app-20150702145346-0002/28 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:34] [Logging$class:logError:75] Asked to remove non-existent executor 28
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/32 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/32 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/31 is now RUNNING
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/31 is now LOADING
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/32 is now LOADING
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/30 because it is EXITED
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/33 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/32 is now RUNNING
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/30 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor app-20150702145346-0002/30 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:34] [Logging$class:logError:75] Asked to remove non-existent executor 30
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/33 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/33 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/33 is now LOADING
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/33 is now RUNNING
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor app-20150702145346-0002/33 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/36 for PageRank
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "36" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  FO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor app-20150702145346-0002/31 removed: Command exited with code 1
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/31 because it is EXITED
  [ERROR] [2015-07-02 14:54:35] [Logging$class:logError:75] Asked to remove non-existent executor 31
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/35 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/35 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/35 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/33 because it is EXITED
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/36 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/34 is now LOADING
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/33 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor app-20150702145346-0002/33 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:35] [Logging$class:logError:75] Asked to remove non-existent executor 33
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/36 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor app-20150702145346-0002/34 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/37 for PageRank
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucle[INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Executor app-20150702145346-0002/36 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/39 for PageRank
  [INFO ] [2015-07-02 14:54:32] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "39" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  45346-0002/37 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/36 because it is EXITED
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/37 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/39 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/35 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor app-20150702145346-0002/35 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:35] [Logging$class:logError:75] Asked to remove non-existent executor 35
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/38 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/38 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/36 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor app-20150702145346-0002/36 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:35] [Logging$class:logError:75] Asked to remove non-existent executor 36
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/39 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/39 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/37 is now LOADING
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/37 is now RUNNING
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor app-20150702145346-0002/37 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/40 for PageRank
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.[INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor app-20150702145346-0002/38 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/42 for PageRank
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "42" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/40 is now RUNNING
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/39 because it is EXITED
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/41 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/39 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor app-20150702145346-0002/39 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:36] [Logging$class:logError:75] Asked to remove non-existent executor 39
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/41 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/41 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Executor app-20150702145346-0002/40 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/43 for PageRank
  [INFO ] [2015-07-02 14:54:33] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "43" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  or ID app-20150702145346-0002/42 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/42 is now LOADING
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/42 is now RUNNING
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/40 because it is EXITED
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/43 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/40 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor app-20150702145346-0002/40 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:36] [Logging$class:logError:75] Asked to remove non-existent executor 40
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/43 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/43 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/43 is now LOADING
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/43 is now RUNNING
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Executor app-20150702145346-0002/43 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/44 for PageRank
  [INFO ] [2015-07-02 14:54:34] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "44" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/44 is now LOADING
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor app-20150702145346-0002/44 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/45 for PageRank
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "45" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/45 is now RUNNING
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Executor app-20150702145346-0002/45 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/46 for PageRank
  [INFO ] [2015-07-02 14:54:35] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "46" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/46 is now LOADING
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Executor app-20150702145346-0002/46 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/47 for PageRank
  [INFO ] [2015-07-02 14:54:36] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "47" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  rt 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/47 is now LOADING
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/47 is now RUNNING
  [INFO ] [2015-07-02 14:54:37] [Logging$class:logInfo:59] Executor app-20150702145346-0002/47 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:37] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/48 for PageRank
  [INFO ] [2015-07-02 14:54:37] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "48" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/48 is now LOADING
  [INFO ] [2015-07-02 14:54:37] [Logging$class:logInfo:59] Executor app-20150702145346-0002/48 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:37] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/49 for PageRank
  [INFO ] [2015-07-02 14:54:37] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "49" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/49 is now LOADING
  [INFO ] [2015-07-02 14:54:38] [Logging$class:logInfo:59] Executor app-20150702145346-0002/49 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:38] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/50 for PageRank
  [INFO ] [2015-07-02 14:54:38] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "50" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/50 is now LOADING
  [INFO ] [2015-07-02 14:54:38] [Logging$class:logInfo:59] Executor app-20150702145346-0002/50 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:38] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/51 for PageRank
  [INFO ] [2015-07-02 14:54:38] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "51" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/51 is now LOADING
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Executor app-20150702145346-0002/51 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/52 for PageRank
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "52" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/52 is now LOADING
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Executor app-20150702145346-0002/52 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/54 for PageRank
  [INFO ] [2015-07-02 14:54:39] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "54" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/53 is now RUNNING
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/52 because it is EXITED
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/54 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/52 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor app-20150702145346-0002/52 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:42] [Logging$class:logError:75] Asked to remove non-existent executor 52
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/54 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Executor app-20150702145346-0002/53 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/55 for PageRank
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/s[INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Executor app-20150702145346-0002/54 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/56 for PageRank
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "56" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/55 is now LOADING
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/54 because it is EXITED
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/56 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/54 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor app-20150702145346-0002/54 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:42] [Logging$class:logError:75] Asked to remove non-existent executor 54
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/56 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/56 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/56 is now RUNNING
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/56 is now LOADING
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Executor app-20150702145346-0002/55 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/58 for PageRank
  [INFO ] [2015-07-02 14:54:40] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "58" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/57 is now RUNNING
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/55 because it is EXITED
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/58 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/55 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Executor app-20150702145346-0002/55 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:43] [Logging$class:logError:75] Asked to remove non-existent executor 55
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/58 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/58 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Executor app-20150702145346-0002/57 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Asked to la[INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Executor app-20150702145346-0002/58 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/60 for PageRank
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "60" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/59 is now RUNNING
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Executor app-20150702145346-0002/59 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/61 for PageRank
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "61" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/60 is now LOADING
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Executor app-20150702145346-0002/60 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/63 for PageRank
  [INFO ] [2015-07-02 14:54:41] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "63" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  7-02 14:54:41] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "62" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  45346-0002/62 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/62 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/62 is now LOADING
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/62 is now RUNNING
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor app-20150702145346-0002/61 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/64 for PageRank
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m"[INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Executor app-20150702145346-0002/62 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/65 for PageRank
  [INFO ] [2015-07-02 14:54:42] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "65" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  45346-0002/64 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/64 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/64 is now LOADING
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/64 is now RUNNING
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/62 because it is EXITED
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/65 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/62 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor app-20150702145346-0002/62 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:44] [Logging$class:logError:75] Asked to remove non-existent executor 62
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/65 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/65 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/65 is now LOADING
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/65 is now RUNNING
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor app-20150702145346-0002/65 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/70 for PageRank
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "70" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/66 is now LOADING
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Executor app-20150702145346-0002/66 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/67 for PageRank
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "67" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/67 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/67 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/67 is now LOADING
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/67 is now RUNNING
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Executor app-20150702145346-0002/67 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/68 for PageRank
  [INFO ] [2015-07-02 14:54:43] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "68" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/68 is now RUNNING
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor app-20150702145346-0002/68 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/69 for PageRank
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "69" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/69 is now LOADING
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Executor app-20150702145346-0002/69 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/71 for PageRank
  [INFO ] [2015-07-02 14:54:44] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "71" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/70 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/69 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor app-20150702145346-0002/69 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:47] [Logging$class:logError:75] Asked to remove non-existent executor 69
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/71 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/71 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/70 is now LOADING
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/71 is now LOADING
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/70 is now RUNNING
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/71 is now RUNNING
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Executor app-20150702145346-0002/70 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/73 for PageRank
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "73" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/72 is now RUNNING
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/70 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/70 because it is EXITED
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Executor app-20150702145346-0002/70 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:48] [Logging$class:logError:75] Asked to remove non-existent executor 70
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/73 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/73 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/73 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/73 is now RUNNING
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Executor app-20150702145346-0002/72 finished with state EXITED[INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Executor app-20150702145346-0002/73 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/75 for PageRank
  [INFO ] [2015-07-02 14:54:45] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "75" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/74 is now LOADING
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/73 because it is EXITED
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Executor app-20150702145346-0002/74 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/76 for PageRank
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "76" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkW[INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Executor app-20150702145346-0002/75 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/77 for PageRank
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "77" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/76 is now RUNNING
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Executor app-20150702145346-0002/76 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/78 for PageRank
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "78" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/77 is now RUNNING
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Executor app-20150702145346-0002/77 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:46] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/79 for PageRank
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "79" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/78 is now LOADING
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor app-20150702145346-0002/78 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/80 for PageRank
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "80" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/79 is now LOADING
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor app-20150702145346-0002/79 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/81 for PageRank
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "81" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/80 is now RUNNING
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor app-20150702145346-0002/80 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/83 for PageRank
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "83" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  Logging$class:logInfo:59] Executor app-20150702145346-0002/63 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/82 for PageRank
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "82" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/82 is now LOADING
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/82 is now RUNNING
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Executor app-20150702145346-0002/82 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:47] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/84 for PageRank
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "84" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/83 is now LOADING
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/82 because it is EXITED
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/84 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/82 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor app-20150702145346-0002/82 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:50] [Logging$class:logError:75] Asked to remove non-existent executor 82
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/81 because it is EXITED
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/85 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/84 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/84 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/81 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor app-20150702145346-0002/81 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:50] [Logging$class:logError:75] Asked to remove non-existent executor 81
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/85 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/85 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/84 is now RUNNING
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/85 is now LOADING
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Executor app-20150702145346-0002/85 finished with state EXITED[INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Executor app-20150702145346-0002/84 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/87 for PageRank
  [INFO ] [2015-07-02 14:54:48] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "87" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/86 is now RUNNING
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/86 is now LOADING
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/84 because it is EXITED
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/87 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Executor app-20150702145346-0002/86 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/88 for PageRank
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/C[INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Executor app-20150702145346-0002/87 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/89 for PageRank
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "89" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/88 is now RUNNING
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/87 because it is EXITED
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/87 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Executor app-20150702145346-0002/87 removed: Command exited with code 1
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/89 on worker worker-20150702134136-10.0.0.41-54339
  [ERROR] [2015-07-02 14:54:51] [Logging$class:logError:75] Asked to remove non-existent executor 87
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/89 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/89 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Executor app-20150702145346-0002/88 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Asked to la[INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Executor app-20150702145346-0002/89 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/91 for PageRank
  [INFO ] [2015-07-02 14:54:49] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "91" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/90 is now LOADING
  [INFO ] [2015-07-02 14:54:52] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/89 because it is EXITED
  [INFO ] [2015-07-02 14:54:52] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/91 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Executor app-20150702145346-0002/90 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/92 for PageRank
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "92" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  14:54:50] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/93 for PageRank
  [INFO ] [2015-07-02 14:54:50] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "93" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  :53] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/93 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/91 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor app-20150702145346-0002/91 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:53] [Logging$class:logError:75] Asked to remove non-existent executor 91
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/93 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/93 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/92 is now RUNNING
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/92 is now LOADING
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/93 is now RUNNING
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/93 is now LOADING
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Executor app-20150702145346-0002/92 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/95 for PageRank
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "95" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  rt 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/92 because it is EXITED
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/95 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/92 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor app-20150702145346-0002/92 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:53] [Logging$class:logError:75] Asked to remove non-existent executor 92
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Executor app-20150702145346-0002/94 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/96 for PageRank
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/[INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Executor app-20150702145346-0002/95 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:51] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/97 for PageRank
  [INFO ] [2015-07-02 14:54:52] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "97" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  5346-0002/94 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:54] [Logging$class:logError:75] Asked to remove non-existent executor 94
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/96 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/96 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/95 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor app-20150702145346-0002/95 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:54] [Logging$class:logError:75] Asked to remove non-existent executor 95
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/97 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/97 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/96 is now RUNNING
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/97 is now LOADING
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/97 is now RUNNING
  [INFO ] [2015-07-02 14:54:52] [Logging$class:logInfo:59] Executor app-20150702145346-0002/97 finished with state EXITED[INFO ] [2015-07-02 14:54:52] [Logging$class:logInfo:59] Executor app-20150702145346-0002/83 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:52] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/100 for PageRank
  [INFO ] [2015-07-02 14:54:52] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "100" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  gging$class:logInfo:59] Granted executor ID app-20150702145346-0002/98 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/97 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor app-20150702145346-0002/97 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:55] [Logging$class:logError:75] Asked to remove non-existent executor 97
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/99 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/83 because it is EXITED
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/99 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/83 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor app-20150702145346-0002/83 removed: Command exited with code 1
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/100 on worker worker-20150702134136-10.0.0.42-55556
  [ERROR] [2015-07-02 14:54:55] [Logging$class:logError:75] Asked to remove non-existent executor 83
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/100 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/100 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/98 is now LOADING
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/98 is now RUNNING
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor app-20150702145346-0002/98 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/101 for PageRank
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Launch[INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Executor app-20150702145346-0002/99 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/103 for PageRank
  [INFO ] [2015-07-02 14:54:53] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "103" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
   [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/100 because it is EXITED
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/101 is now RUNNING
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/102 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/100 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/100 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:56] [Logging$class:logError:75] Asked to remove non-existent executor 100
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/102 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/102 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/99 because it is EXITED
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/99 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/99 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:56] [Logging$class:logError:75] Asked to remove non-existent executor 99
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/103 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/103 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/103 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor app-20150702145346-0002/101 finished with state EXITED[INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor app-20150702145346-0002/102 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/105 for PageRank
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Launch [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor app-20150702145346-0002/103 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/106 for PageRank
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "106" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/104 is now RUNNING
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/102 because it is EXITED
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/102 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/102 removed: Command exited with code 1
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/105 on worker worker-20150702134136-10.0.0.42-55556
  [ERROR] [2015-07-02 14:54:56] [Logging$class:logError:75] Asked to remove non-existent executor 102
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/105 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/105 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/104 is now LOADING
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/105 is now LOADING
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/105 is now RUNNING
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor app-20150702145346-0002/105 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/109 for PageRank
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "109" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  57] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/106 is now RUNNING
  [INFO ] [2015-07-02 14:54:54] [Logging$class:logInfo:59] Executor app-20150702145346-0002/106 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/108 for PageRank
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "108" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.[INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor app-20150702145346-0002/107 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/110 for PageRank
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "110" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  57] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/108 is now RUNNING
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/108 is now LOADING
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/105 because it is EXITED
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/109 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Executor app-20150702145346-0002/108 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/111 for PageRank
  [INFO ] [2015-07-02 14:54:55] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "111" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
    [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor app-20150702145346-0002/107 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:58] [Logging$class:logError:75] Asked to remove non-existent executor 107
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/110 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/110 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/109 is now LOADING
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/109 is now RUNNING
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/110 is now LOADING
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/110 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/114 for PageRank
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "114" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  58] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/111 is now LOADING
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/111 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/113 for PageRank
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "113" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.[INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/112 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/115 for PageRank
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "115" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  0702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/113 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/110 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor app-20150702145346-0002/110 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:58] [Logging$class:logError:75] Asked to remove non-existent executor 110
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/114 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/114 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/114 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/113 is now RUNNING
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/113 is now LOADING
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/114 is now LOADING
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/114 is now RUNNING
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/113 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/116 for PageRank
  [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "116" [INFO ] [2015-07-02 14:54:56] [Logging$class:logInfo:59] Executor app-20150702145346-0002/114 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/118 for PageRank
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "118" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  --cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/116 is now RUNNING
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/115 because it is EXITED
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/116 is now LOADING
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Executor app-20150702145346-0002/116 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/119 for PageRank
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "119" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  B RAM
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/114 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor app-20150702145346-0002/114 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:54:59] [Logging$class:logError:75] Asked to remove non-existent executor 114
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/118 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/118 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/117 is now RUNNING
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Executor app-20150702145346-0002/117 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/120 for PageRank
  [INFO ] [2015-07-02 14:54:57] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "120" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  xecutor ID app-20150702145346-0002/119 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/119 is now LOADING
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/119 is now RUNNING
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor app-20150702145346-0002/119 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/121 for PageRank
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "121" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  00] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/120 is now RUNNING
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/119 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Executor app-20150702145346-0002/119 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:00] [Logging$class:logError:75] Asked to remove non-existent executor 119
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/119 because it is EXITED
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/121 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/121 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/121 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Executor app-20150702145346-0002/120 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/123 for PageRank
  [INFO ] [2015-07-02 14:54:58] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "123" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  4139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/120 because it is EXITED
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/122 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/120 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor app-20150702145346-0002/120 removed: Command exited with code 1
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/123 on worker worker-20150702134136-10.0.0.42-55556
  [ERROR] [2015-07-02 14:55:01] [Logging$class:logError:75] Asked to remove non-existent executor 120
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/123 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/123 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/122 is now LOADING
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/122 is now RUNNING
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/123 is now LOADING
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/123 is now RUNNING
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor app-20150702145346-0002/123 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/125 for PageRank
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "125" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  14:55:01] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/125 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/123 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor app-20150702145346-0002/123 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:01] [Logging$class:logError:75] Asked to remove non-existent executor 123
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/125 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/125 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/124 is now RUNNING
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/124 is now LOADING
  [INFO ] [2015-07-02 14:54:59] [Logging$class:logInfo:59] Executor app-20150702145346-0002/125 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/127 for PageRank
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "127" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  xecutor ID app-20150702145346-0002/126 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/126 is now LOADING
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/126 is now RUNNING
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/125 because it is EXITED
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/127 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Executor app-20150702145346-0002/126 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/129 for PageRank
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "or[INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Executor app-20150702145346-0002/127 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/128 for PageRank
  [INFO ] [2015-07-02 14:55:00] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "128" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  nching executor app-20150702145346-0002/129 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/128 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/126 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor app-20150702145346-0002/126 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:03] [Logging$class:logError:75] Asked to remove non-existent executor 126
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/129 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/129 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/128 is now LOADING
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Executor app-20150702145346-0002/128 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/131 for PageRank
  [INFO ] [2015-07-02 14:55:01] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "131" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  4139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/130 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/128 because it is EXITED
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/131 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/128 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor app-20150702145346-0002/128 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:03] [Logging$class:logError:75] Asked to remove non-existent executor 128
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/131 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/131 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/130 is now LOADING
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/130 is now RUNNING
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/131 is now RUNNING
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/131 is now LOADING
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Executor app-20150702145346-0002/130 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/133 for PageRank
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "133" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  04] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/130 because it is EXITED
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/133 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Executor app-20150702145346-0002/132 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/134 for PageRank
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "134" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  $class:logInfo:59] Executor app-20150702145346-0002/132 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:05] [Logging$class:logError:75] Asked to remove non-existent executor 132
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/132 because it is EXITED
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/134 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/134 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/134 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:02] [Logging$class:logInfo:59] Executor app-20150702145346-0002/133 finished with state EXITED[INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor app-20150702145346-0002/134 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/136 for PageRank
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "136" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  xecutor ID app-20150702145346-0002/135 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/134 because it is EXITED
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/136 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/135 is now LOADING
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor app-20150702145346-0002/135 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/138 for PageRank
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-[INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Executor app-20150702145346-0002/136 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/139 for PageRank
  [INFO ] [2015-07-02 14:55:03] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "139" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  l" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "137" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  06] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/135 because it is EXITED
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/137 is now RUNNING
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/137 is now LOADING
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/135 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/135 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:06] [Logging$class:logError:75] Asked to remove non-existent executor 135
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/138 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/138 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/138 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/136 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/136 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:06] [Logging$class:logError:75] Asked to remove non-existent executor 136
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Executor app-20150702145346-0002/137 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/142 for PageRank
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "142" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  eRank
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "141" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  or updated: app-20150702145346-0002/138 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/138 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:06] [Logging$class:logError:75] Asked to remove non-existent executor 138
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/140 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/140 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/139 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/139 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:06] [Logging$class:logError:75] Asked to remove non-existent executor 139
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/141 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/141 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/137 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/137 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:06] [Logging$class:logError:75] Asked to remove non-existent executor 137
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/142 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/142 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/140 is now LOADING
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/140 is now RUNNING
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Executor app-20150702145346-0002/140 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/143 for PageRank
  [INFO ] [2015-07-02 14:55:04] [Logging$class:logInfo:59] Launch [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Executor app-20150702145346-0002/142 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/145 for PageRank
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "145" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  07] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/141 because it is EXITED
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/144 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/141 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor app-20150702145346-0002/141 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:07] [Logging$class:logError:75] Asked to remove non-existent executor 141
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/144 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/144 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Executor app-20150702145346-0002/143 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Asked to lau[INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Executor app-20150702145346-0002/144 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/147 for PageRank
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "147" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  07] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/144 is now LOADING
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Executor app-20150702145346-0002/145 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/148 for PageRank
  [INFO ] [2015-07-02 14:55:05] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "148" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  orker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/146 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/146 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/144 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor app-20150702145346-0002/144 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:08] [Logging$class:logError:75] Asked to remove non-existent executor 144
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/147 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/147 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/146 is now LOADING
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/147 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/150 for PageRank
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "150" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  4136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/148 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/148 is now RUNNING
  [WARN ] [2015-07-02 14:55:08] [Logging$class:logWarning:71] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/146 because it is EXITED
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/148 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/151 for PageRank
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "151" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  B RAM
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/148 is now LOADING
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/147 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor app-20150702145346-0002/147 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:08] [Logging$class:logError:75] Asked to remove non-existent executor 147
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/150 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/150 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:06] [Logging$class:logInfo:59] Executor app-20150702145346-0002/149 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/152 for PageRank
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "152" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
 [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor app-20150702145346-0002/151 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/153 for PageRank
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "153" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  09] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/152 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/152 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/151 is now RUNNING
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/152 is now LOADING
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/151 because it is EXITED
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/153 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/151 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Executor app-20150702145346-0002/151 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:09] [Logging$class:logError:75] Asked to remove non-existent executor 151
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/153 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/153 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor app-20150702145346-0002/152 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Asked to lau[INFO ] [2015-07-02 14:55:07] [Logging$class:logInfo:59] Executor app-20150702145346-0002/153 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/155 for PageRank
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "155" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  0702145346-0002/154 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/154 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/153 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor app-20150702145346-0002/153 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:10] [Logging$class:logError:75] Asked to remove non-existent executor 153
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/155 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/155 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/154 is now LOADING
  [INFO ] [2015-07-02 14:55:08] [Logging$class:logInfo:59] Executor app-20150702145346-0002/155 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/157 for PageRank
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "157" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  702145346-0002/154 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:11] [Logging$class:logError:75] Asked to remove non-existent executor 154
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/156 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/156 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/155 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Executor app-20150702145346-0002/155 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:11] [Logging$class:logError:75] Asked to remove non-existent executor 155
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/157 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/157 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Executor app-20150702145346-0002/156 finished with state EXITED[INFO ] [2015-07-02 14:55:09] [Logging$class:logInfo:59] Executor app-20150702145346-0002/157 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/159 for PageRank
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "159" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  xecutor ID app-20150702145346-0002/158 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/157 is now LOADING
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor app-20150702145346-0002/158 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/160 for PageRank
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "160" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  xecutor ID app-20150702145346-0002/159 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor app-20150702145346-0002/159 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/162 for PageRank
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "162" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  xecutor ID app-20150702145346-0002/160 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Executor app-20150702145346-0002/160 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/161 for PageRank
  [INFO ] [2015-07-02 14:55:10] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "161" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  xecutor ID app-20150702145346-0002/161 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/161 is now LOADING
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/161 is now RUNNING
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Executor app-20150702145346-0002/161 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/163 for PageRank
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "163" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  13] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/162 is now LOADING
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Executor app-20150702145346-0002/162 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/164 for PageRank
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "164" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  14] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/163 is now RUNNING
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Executor app-20150702145346-0002/163 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/165 for PageRank
  [INFO ] [2015-07-02 14:55:11] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "165" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  14] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/164 is now LOADING
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Executor app-20150702145346-0002/164 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/166 for PageRank
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "166" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  14] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/165 is now LOADING
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Executor app-20150702145346-0002/165 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/167 for PageRank
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "167" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  14] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/166 is now LOADING
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/165 because it is EXITED
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/167 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/165 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor app-20150702145346-0002/165 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:14] [Logging$class:logError:75] Asked to remove non-existent executor 165
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/167 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/167 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Executor app-20150702145346-0002/166 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:12] [Logging$class:logInfo:59] Asked to lau[INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Executor app-20150702145346-0002/167 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/169 for PageRank
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "169" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.[INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Executor app-20150702145346-0002/168 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/170 for PageRank
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "170" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  15] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/169 is now LOADING
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/169 is now RUNNING
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Executor app-20150702145346-0002/169 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/171 for PageRank
  [INFO ] [2015-07-02 14:55:13] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "171" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  15] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/170 is now RUNNING
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor app-20150702145346-0002/170 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/172 for PageRank
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "172" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  16] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/171 is now RUNNING
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor app-20150702145346-0002/171 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/173 for PageRank
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "173" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  16] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/172 is now RUNNING
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor app-20150702145346-0002/172 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/174 for PageRank
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "174" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  17] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/173 is now RUNNING
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor app-20150702145346-0002/173 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/176 for PageRank
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "176" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  th code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/175 for PageRank
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "175" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  17] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/174 is now LOADING
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/175 is now LOADING
  [INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor app-20150702145346-0002/174 finished with state EXITED[INFO ] [2015-07-02 14:55:14] [Logging$class:logInfo:59] Executor app-20150702145346-0002/175 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/177 for PageRank
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "177" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  17] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/176 is now LOADING
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Executor app-20150702145346-0002/176 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/179 for PageRank
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "179" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  17] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/177 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/174 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Executor app-20150702145346-0002/174 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:17] [Logging$class:logError:75] Asked to remove non-existent executor 174
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/178 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/178 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/177 is now LOADING
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Executor app-20150702145346-0002/178 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/181 for PageRank
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "181" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "180" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  17] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/179 is now RUNNING
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Executor app-20150702145346-0002/179 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/182 for PageRank
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "182" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  18] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/178 because it is EXITED
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/181 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/180 is now RUNNING
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/178 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor app-20150702145346-0002/178 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:18] [Logging$class:logError:75] Asked to remove non-existent executor 178
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/181 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/181 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/181 is now LOADING
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Executor app-20150702145346-0002/180 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/183 for PageRank
  [INFO ] [2015-07-02 14:55:15] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "183" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  18] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/182 is now RUNNING
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/182 is now LOADING
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/180 because it is EXITED
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/183 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/180 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor app-20150702145346-0002/180 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:18] [Logging$class:logError:75] Asked to remove non-existent executor 180
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/183 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Executor app-20150702145346-0002/182 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/184 for PageRank
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/sp[INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Executor app-20150702145346-0002/183 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/185 for PageRank
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "185" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  19] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/183 because it is EXITED
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/185 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/184 is now RUNNING
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/183 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor app-20150702145346-0002/183 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:19] [Logging$class:logError:75] Asked to remove non-existent executor 183
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/185 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/185 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/185 is now RUNNING
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/185 is now LOADING
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Executor app-20150702145346-0002/184 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/187 for PageRank
  [INFO ] [2015-07-02 14:55:16] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "187" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  19] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/184 because it is EXITED
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/187 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/186 is now RUNNING
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/184 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor app-20150702145346-0002/184 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:19] [Logging$class:logError:75] Asked to remove non-existent executor 184
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/187 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/187 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/187 is now LOADING
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Executor app-20150702145346-0002/186 finished with state EXITED[INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Executor app-20150702145346-0002/187 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/190 for PageRank
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "190" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  17] [Logging$class:logInfo:59] Executor app-20150702145346-0002/188 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/189 for PageRank
  [INFO ] [2015-07-02 14:55:17] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "189" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  20] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/187 because it is EXITED
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/190 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/187 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor app-20150702145346-0002/187 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:20] [Logging$class:logError:75] Asked to remove non-existent executor 187
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/190 on worker-20150702134139-10.0.0.39-60045 (10.0.0.39:60045) with 4 cores
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/190 on hostPort 10.0.0.39:60045 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/189 is now LOADING
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/189 is now RUNNING
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/190 is now RUNNING
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor app-20150702145346-0002/189 finished with state EXITED[INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor app-20150702145346-0002/190 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/192 for PageRank
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "192" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  20] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/191 is now RUNNING
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Executor app-20150702145346-0002/191 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/193 for PageRank
  [INFO ] [2015-07-02 14:55:18] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "193" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  21] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/192 is now RUNNING
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor app-20150702145346-0002/192 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/194 for PageRank
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "194" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.[INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor app-20150702145346-0002/193 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/195 for PageRank
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "195" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  21] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/193 because it is EXITED
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/193 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Executor app-20150702145346-0002/193 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:21] [Logging$class:logError:75] Asked to remove non-existent executor 193
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Executor app-20150702145346-0002/194 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/196 for PageRank
  [INFO ] [2015-07-02 14:55:19] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "196" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  Info:59] Launching executor app-20150702145346-0002/196 on worker worker-20150702134139-10.0.0.39-60045
  [INFO ] [2015-07-02 14:55:22] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/194 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:22] [Logging$class:logInfo:59] Executor app-20150702145346-0002/194 removed: Command exited with code 1
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor app-20150702145346-0002/195 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/197 for PageRank
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1[INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor app-20150702145346-0002/196 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/198 for PageRank
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "198" "--hostname" "10.0.0.39" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.39:60045/user/Worker"
  22] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/197 is now RUNNING
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Executor app-20150702145346-0002/197 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/199 for PageRank
  [INFO ] [2015-07-02 14:55:20] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "199" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  23] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/198 is now LOADING
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/197 because it is EXITED
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/199 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/197 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor app-20150702145346-0002/197 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:23] [Logging$class:logError:75] Asked to remove non-existent executor 197
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/199 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/199 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/199 is now RUNNING
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/199 is now LOADING
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Executor app-20150702145346-0002/199 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/200 for PageRank
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "200" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  stPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/200 is now RUNNING
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/200 is now LOADING
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Executor app-20150702145346-0002/200 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/201 for PageRank
  [INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "201" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.[INFO ] [2015-07-02 14:55:21] [Logging$class:logInfo:59] Executor app-20150702145346-0002/181 finished with state EXITED[INFO ] [2015-07-02 14:55:22] [Logging$class:logInfo:59] Executor app-20150702145346-0002/201 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:22] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/203 for PageRank
  [INFO ] [2015-07-02 14:55:22] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "203" "--hostname" "10.0.0.42" "[INFO ] [2015-07-02 14:55:22] [Logging$class:logInfo:59] Executor app-20150702145346-0002/202 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:22] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/204 for PageRank
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "204" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  xecutor ID app-20150702145346-0002/203 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor app-20150702145346-0002/203 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/205 for PageRank
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "205" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  xecutor ID app-20150702145346-0002/204 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/204 is now LOADING
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/203 because it is EXITED
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/205 on worker worker-20150702134136-10.0.0.42-55556
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/204 is now RUNNING
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/203 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor app-20150702145346-0002/203 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:25] [Logging$class:logError:75] Asked to remove non-existent executor 203
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/205 on worker-20150702134136-10.0.0.42-55556 (10.0.0.42:55556) with 4 cores
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/205 on hostPort 10.0.0.42:55556 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor app-20150702145346-0002/204 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Asked to lau[INFO ] [2015-07-02 14:55:23] [Logging$class:logInfo:59] Executor app-20150702145346-0002/205 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/207 for PageRank
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "207" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  26] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/206 is now LOADING
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Executor app-20150702145346-0002/206 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/209 for PageRank
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "209" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  27] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/207 is now LOADING
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Executor app-20150702145346-0002/207 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/208 for PageRank
  [INFO ] [2015-07-02 14:55:24] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "208" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  27] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/208 is now LOADING
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/206 because it is EXITED
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/206 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/209 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor app-20150702145346-0002/206 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:27] [Logging$class:logError:75] Asked to remove non-existent executor 206
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/209 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/209 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/209 is now LOADING
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/209 is now RUNNING
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor app-20150702145346-0002/209 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/211 for PageRank
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "211" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  27] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/209 because it is EXITED
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/211 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/209 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor app-20150702145346-0002/209 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:27] [Logging$class:logError:75] Asked to remove non-existent executor 209
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor added: app-20150702145346-0002/211 on worker-20150702134136-10.0.0.41-54339 (10.0.0.41:54339) with 4 cores
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Granted executor ID app-20150702145346-0002/211 on hostPort 10.0.0.41:54339 with 4 cores, 8.7 GB RAM
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor app-20150702145346-0002/210 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/212 for PageRank
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Launch [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Executor app-20150702145346-0002/211 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/213 for PageRank
  [INFO ] [2015-07-02 14:55:25] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "213" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  28] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/212 is now LOADING
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Executor app-20150702145346-0002/212 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/214 for PageRank
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "214" "--hostname" "10.0.0.42" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.42:55556/user/Worker"
  28] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/213 is now LOADING
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Executor app-20150702145346-0002/213 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Asked to launch executor app-20150702145346-0002/215 for PageRank
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Launch command: "/usr/bin/java" "-cp" "/home/spark/spark-1.3.1/sbin/../conf/:/home/spark/spark-1.3.1/assembly/target/scala-2.10/spark-assembly-1.4.0-hadoop2.2.0.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/spark/spark-1.3.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/spark/hadoop-1.2.1/conf/" "-Xms8900M" "-Xmx8900M" "-Dspark.driver.port=60939" "-XX:MaxPermSize=128m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@10.0.0.38:60939/user/CoarseGrainedScheduler" "--executor-id" "215" "--hostname" "10.0.0.41" "--cores" "4" "--app-id" "app-20150702145346-0002" "--worker-url" "akka.tcp://sparkWorker@10.0.0.41:54339/user/Worker"
  28] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/214 is now LOADING
  [INFO ] [2015-07-02 14:55:28] [Logging$class:logInfo:59] Removing executor app-20150702145346-0002/213 because it is EXITED
  [INFO ] [2015-07-02 14:55:28] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/213 is now EXITED (Command exited with code 1)
  [INFO ] [2015-07-02 14:55:28] [Logging$class:logInfo:59] Executor app-20150702145346-0002/213 removed: Command exited with code 1
  [ERROR] [2015-07-02 14:55:28] [Logging$class:logError:75] Asked to remove non-existent executor 213
  [INFO ] [2015-07-02 14:55:28] [Logging$class:logInfo:59] Launching executor app-20150702145346-0002/215 on worker worker-20150702134136-10.0.0.41-54339
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Executor app-20150702145346-0002/214 finished with state EXITED message Command exited with code 1 exitStatus 1
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Asked to kill unknown executor app-20150702145346-0002/214
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702145346-0002
  own hook
  [INFO ] [2015-07-02 14:55:28] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/215 is now RUNNING
  [INFO ] [2015-07-02 14:55:28] [Logging$class:logInfo:59] Executor updated: app-20150702145346-0002/215 is now LOADING
  [INFO ] [2015-07-02 14:55:28] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
  [INFO ] [2015-07-02 14:55:28] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
  [INFO ] [2015-07-02 14:55:28] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/api,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/static,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/executors/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/executors,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/environment/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/environment,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/storage/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/storage,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/stages/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/stages,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
  [INFO ] [2015-07-02 14:55:29] [ContextHandler:doStop:843] stopped o.s.j.s.ServletContextHandler{/jobs,null}
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Stopped Spark web UI at http://10.0.0.38:4040
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Stopping DAGScheduler
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Job 0 failed: collect at SparkPageRank.scala:71, took 95.646517 s
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] ShuffleMapStage 0 (distinct at SparkPageRank.scala:60) failed in 95.368 s
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Shutting down all executors
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Asking each executor to shut down
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Asked to kill executor app-20150702145346-0002/215
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Runner thread for executor app-20150702145346-0002/215 interrupted
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor app-20150702145346-0002/215 finished with state KILLED exitStatus 1
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702145346-0002
  ] MemoryStore cleared
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] BlockManager stopped
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] BlockManagerMaster stopped
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] OutputCommitCoordinator stopped!
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Successfully stopped SparkContext
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Shutdown hook called
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] Deleting directory /tmp/spark-841310c3-faa1-42c0-adfe-538b17386b10
  [WARN ] [2015-07-02 14:55:29] [Logging$class:logWarning:71] Application PageRank is still in progress, it may be terminated abnormally.
  [WARN ] [2015-07-02 14:55:29] [Logging$class:logWarning:71] No event logs found for application PageRank in file:///home/spark/history-spark.
  [WARN ] [2015-07-02 14:55:29] [Logging$class:logWarning:71] Got status update for unknown executor app-20150702145346-0002/214
  [INFO ] [2015-07-02 14:55:26] [Logging$class:logInfo:59] Asked to kill executor app-20150702145346-0002/198
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Runner thread for executor app-20150702145346-0002/198 interrupted
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Killing process!
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Executor app-20150702145346-0002/198 finished with state KILLED exitStatus 143
  [INFO ] [2015-07-02 14:55:27] [Logging$class:logInfo:59] Cleaning up local directories for application app-20150702145346-0002
  us update for unknown executor app-20150702145346-0002/198
  [INFO ] [2015-07-02 14:55:29] [Logging$class:logInfo:59] akka.tcp://sparkDriver@10.0.0.38:60939 got disassociated, removing it.
  